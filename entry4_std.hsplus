system "SwarmIntelligence" {
  @swarm_config {
    agent_count: 10000
    agent_type: "simple_reactive"
    emergence_enabled: true
    collective_memory: true
  }
  
  // Individual agent behavior
  template "SwarmAgent" {
    @minimal_brain {
      inputs: ["local_perception", "neighbor_states", "pheromone_signals"]
      outputs: ["movement_vector", "signal_emission", "state_change"]
      rules: 5  // Maximum number of rules per agent
    }
    
    state: {
      position: Vector3,
      velocity: Vector3,
      energy: number,
      role: "explorer",
      carrying: Item | null,
      memory: LimitedMemory(10)
    }
    
    perception: {
      range: 5,
      field_of_view: 270,
      senses: ["visual", "chemical", "contact"]
    }
    
    // Simple rules that create emergent behavior
    @rules {
      rule "separation" {
        condition: "neighbors_too_close(1)"
        action: steer_away_from(closest_neighbor)
        weight: 2.0
      }
      
      rule "alignment" {
        condition: "neighbors.count > 0"
        action: steer_toward(average_neighbor_heading)
        weight: 1.0
      }
      
      rule "cohesion" {
        condition: "neighbors.count > 0"
        action: steer_toward(flock_center)
        weight: 1.0
      }
      
      rule "follow_pheromone" {
        condition: "sense_pheromone(""food") > threshold
        action: steer_toward(pheromone_gradient("food"))
        weight: 1.5
      }
      
      rule "avoid_danger" {
        condition: "sense_pheromone(""danger") > 0 || see_predator()
        action: steer_away(danger_source); emit_pheromone("danger")
        weight: 3.0
      }
    }
  }
  
  // Pheromone system for indirect communication
  @pheromone_system {
    types: [
      { name: "food", decay_rate: 0.01, diffusion_rate: 0.1, max_intensity: 100 }
      { name: "home", decay_rate: 0.005, diffusion_rate: 0.05, max_intensity: 100 }
      { name: "danger", decay_rate: 0.1, diffusion_rate: 0.2, max_intensity: 50 }
      { name: "explore", decay_rate: 0.02, diffusion_rate: 0.15, max_intensity: 30 }
      { name: "recruit", decay_rate: 0.05, diffusion_rate: 0.3, max_intensity: 80 }
    ]
    
    grid_resolution: 0.5  // meters
    update_rate: 10  // Hz
  }
  
  // Emergent collective behaviors
  @emergence_detector {
    // Detect when swarm exhibits higher-order behavior
    
    object "foraging_trail" {
      detection: pheromone_path("food", "home", length > 10)
      emergent_behavior: "optimized_resource_gathering"
      @on_detected {
        log("Swarm has established foraging trail")
        notify_observers("foraging_established")
      }
    }
    
    object "collective_defense" {
      detection: agents_forming_perimeter(center: queen, radius: 5, density > 0.8)
      emergent_behavior: "protective_formation"
      @on_detected {
        log("Defensive formation emerged")
        adjust_role_weights({ defender: +0.5 })
      }
    }
    
    object "swarm_intelligence" {
      detection: collective_decision_made(options > 2, consensus > 0.9)
      emergent_behavior: "democratic_decision"
      measure: decision_quality()
    }
    
    object "task_allocation" {
      detection: agents_specialized(roles.variance > threshold)
      emergent_behavior: "division_of_labor"
    }
    
    object "bridge_formation" {
      detection: agents_forming_structure(connects: gap, load_bearing: true)
      emergent_behavior: "living_bridge"
    }
  }
  
  // Collective memory and learning
  @collective_memory {
    type: "stigmergic"  // Environment-based memory
    
    knowledge_types: [
      { name: "food_locations", encoding: "pheromone_intensity", persistence: 3600 }
      { name: "danger_zones", encoding: "pheromone_intensity", persistence: 7200 }
      { name: "explored_areas", encoding: "pheromone_decay", persistence: 1800 }
    ]
logic {
  function "remember_collectively" : void {
        emit_pheromone(info.type, location, info.intensity)
      }
  function "recall_collectively" : Knowledge {
        return sense_pheromone(type, location)
      }
    }
  }
  
  // Swarm optimization algorithms
  @swarm_optimization {
    object "ant_colony_optimization" {
      use_case: "pathfinding"
logic {
  function "find_optimal_path" : Path {
          // Multiple ants explore simultaneously
          for (iteration in range(100)) {
            for (ant of explorer_agents) {
              const path = ant.find_path(start, end)
              if (path.valid) {
                const quality = 1 / path.length
                ant.deposit_pheromone(path, quality)
              }
            }
            pheromone_system.decay()
          }
        
          return reconstruct_best_path(start, end)
        }
      }
    }
    
    object "particle_swarm_optimization" {
      use_case: "parameter_optimization"
logic {
  function "optimize" : Vector {
          // Each agent is a particle in solution space
          for (agent of agents) {
            agent.position = random_position(dimensions)
            agent.velocity = random_velocity(dimensions)
            agent.personal_best = agent.position
          }
        
          let global_best = find_best(agents, objective)
        
          for (iteration in range(1000)) {
            for (agent of agents) {
              // Update velocity based on personal and global best
              agent.velocity = inertia * agent.velocity
                + cognitive * random() * (agent.personal_best - agent.position)
                + social * random() * (global_best - agent.position)
            
              agent.position += agent.velocity
            
              if (objective(agent.position) > objective(agent.personal_best)) {
                agent.personal_best = agent.position
              }
            }
          
            global_best = find_best(agents, objective)
          }
        
          return global_best
        }
      }
    }
  }
}
