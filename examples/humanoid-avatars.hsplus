/**
 * HoloScript Humanoid Avatar Examples
 *
 * Demonstrates loading and controlling humanoid avatars using:
 * - VRM (Virtual Reality Model) format via @pixiv/three-vrm
 * - Ready Player Me (RPM) avatars
 * - Full integration with HoloScript's humanoid traits
 *
 * @version 1.0.0
 * @requires @holoscript/core >= 2.1.0
 * @requires @pixiv/three-vrm >= 3.0.0 (optional, for VRM support)
 */

// ============================================================================
// EXAMPLE 1: Basic VRM Avatar Loading
// ============================================================================

composition "VRMAvatarDemo" {
  environment {
    skybox: "gradient",
    ambient_light: { color: "#ffffff", intensity: 0.6 }
  }

  state {
    avatarLoaded: false,
    currentExpression: "neutral",
    isWaving: false
  }

  // VRM Avatar with full humanoid traits
  object "MainAvatar" {
    @skeleton {
      rig: "humanoid",
      animations: ["idle", "walk", "wave", "talk"],
      blendTree: {
        type: "1D",
        parameter: "speed",
        clips: [
          { name: "idle", threshold: 0 },
          { name: "walk", threshold: 0.5 },
          { name: "run", threshold: 1.0 }
        ]
      }
    }

    @face {
      expressions: ["happy", "sad", "angry", "surprised", "neutral"],
      blendShapes: true,
      autoBlink: true,
      blinkInterval: [3, 7]
    }

    @expressive {
      lipSync: true,
      eyeTracking: true,
      microExpressions: true
    }

    @body {
      type: "humanoid",
      scale: 1.0
    }

    @locomotion {
      walkSpeed: 1.5,
      runSpeed: 4.0,
      turnSpeed: 180,
      groundCheck: true
    }

    // Model source - VRM file
    model: "https://example.com/avatars/character.vrm",

    position: [0, 0, -3],
    scale: 1.0

    on_mount {
      state.avatarLoaded = true
      self.play("idle")
    }

    on_expression_change(expression) {
      state.currentExpression = expression
    }

    action wave() {
      state.isWaving = true
      self.play("wave", { crossfade: 0.2 })
      await delay(2000)
      self.play("idle", { crossfade: 0.3 })
      state.isWaving = false
    }

    action speak(text) {
      // Lip sync will automatically activate with voice output
      self.setExpression("talk")
      await self.voiceOutput.speak(text)
      self.setExpression("neutral")
    }
  }
}

// ============================================================================
// EXAMPLE 2: Ready Player Me Avatar
// ============================================================================

composition "ReadyPlayerMeDemo" {
  environment {
    skybox: "studio",
    ambient_light: { color: "#f0f0f0", intensity: 0.8 }
  }

  state {
    avatarId: "64f8a1b2c3d4e5f6a7b8c9d0",
    quality: "high"
  }

  // Ready Player Me Avatar with automatic configuration
  object "RPMAvatar" {
    @skeleton { rig: "humanoid" }
    @face {
      expressions: "ARKit",  // Ready Player Me supports ARKit blend shapes
      lipSync: true
    }
    @expressive {
      lipSync: true
    }
    @clothing {
      outfit: "casual",
      customizable: true
    }
    @hair {
      physics: true,
      style: "default"
    }

    // Ready Player Me URL with quality parameters
    model: "https://models.readyplayer.me/${state.avatarId}.glb?quality=high&morphTargets=ARKit,Oculus%20Visemes&textureAtlas=1024",

    position: [0, 0, -2],
    scale: 1.0

    on_mount {
      // RPM avatars come with Mixamo-compatible rig
      self.playAnimation("idle")
    }

    action changeOutfit(outfitId) {
      // RPM supports runtime outfit changes
      await self.loadOutfit(outfitId)
    }
  }

  // UI for avatar customization
  ui {
    element "AvatarControls" {
      type: "panel",
      position: "bottom-center",

      element "ExpressionButtons" {
        type: "button-group",
        buttons: [
          { label: "Happy", action: () => RPMAvatar.setExpression("happy", 1.0) },
          { label: "Sad", action: () => RPMAvatar.setExpression("sad", 1.0) },
          { label: "Surprised", action: () => RPMAvatar.setExpression("surprised", 1.0) },
          { label: "Neutral", action: () => RPMAvatar.setExpression("neutral", 1.0) }
        ]
      }
    }
  }
}

// ============================================================================
// EXAMPLE 3: AI-Driven NPC with Full Embodiment
// ============================================================================

composition "AICompanionDemo" {
  environment {
    skybox: "outdoor_day",
    ambient_light: { color: "#fffaf0", intensity: 0.7 }
  }

  state {
    conversationActive: false,
    companionMood: "friendly",
    playerNearby: false
  }

  // AI Companion NPC with full avatar embodiment
  npc "Aria" {
    type: "companion",
    model: "https://example.com/avatars/aria.vrm",

    @skeleton {
      rig: "humanoid",
      animations: ["idle", "talk", "gesture", "wave", "think", "nod", "shake_head"]
    }

    @face {
      expressions: ["happy", "curious", "thoughtful", "excited", "neutral"],
      autoBlink: true,
      eyeTracking: true
    }

    @expressive {
      lipSync: true,
      microExpressions: true,
      emotionDriven: true
    }

    @avatar_embodiment {
      tracking_source: "ai",
      ik_mode: "upper_body",
      lip_sync: true,
      emotion_directives: true,
      voice_output: {
        engine: "elevenlabs",
        voice: "aria",
        style: "conversational"
      },
      personality: {
        sociability: 0.8,
        warmth: 0.9,
        expressiveness: 0.7,
        energy: 0.6
      },
      conversation_fillers: true
    }

    @character_voice {
      voice: "aria",
      pitch: 1.0,
      speed: 1.0,
      emotion: "adaptive"
    }

    @dialogue {
      personality: "friendly_helper",
      memory: true,
      contextAware: true
    }

    position: [2, 0, -3],
    lookAt: "player"

    // Behavior: Greet when player approaches
    behavior "greet_player" {
      trigger: "on_player_nearby",
      condition: !state.conversationActive && distance(self, player) < 3,
      priority: 10,

      actions: [
        { type: "face", target: "player" },
        { type: "animate", clip: "wave", duration: 1.5 },
        { type: "emit", event: "greet", data: { mood: state.companionMood } }
      ]
    }

    // Behavior: Idle animations when not in conversation
    behavior "idle_behavior" {
      trigger: "on_idle",
      condition: !state.conversationActive,
      priority: 1,

      actions: [
        { type: "animate", clip: "idle" },
        { type: "wait", duration: [5, 10] },
        { type: "animate", clip: "think", duration: 2 }
      ]
    }

    on_player_nearby {
      state.playerNearby = true
      if (!state.conversationActive) {
        self.trigger("greet_player")
      }
    }

    on_player_leave {
      state.playerNearby = false
    }

    on_dialogue_start {
      state.conversationActive = true
      self.setExpression("curious")
    }

    on_dialogue_end {
      state.conversationActive = false
      self.setExpression("happy")
      self.playAnimation("nod")
    }

    // AI response handler with embodiment
    action respond(userInput) {
      // Show thinking state
      self.setExpression("thoughtful")
      self.playAnimation("think")

      // Get AI response with emotion tags
      const response = await llm.generate({
        prompt: userInput,
        persona: "aria_companion",
        includeEmotionTags: true
      })

      // Parse emotion from response
      const emotion = response.emotionTag || "neutral"
      self.setExpression(emotion)

      // Speak with lip sync and gestures
      await self.speak(response.text, {
        gestures: true,
        emotionDriven: true
      })
    }
  }
}

// ============================================================================
// EXAMPLE 4: Multiplayer Avatar Sync
// ============================================================================

composition "MultiplayerAvatars" {
  environment {
    skybox: "virtual_space"
  }

  state {
    localPlayerId: null,
    remotePlayers: {}
  }

  // Local player avatar
  object "LocalPlayer" {
    @skeleton { rig: "humanoid" }
    @face { expressions: "full" }
    @expressive { lipSync: true }
    @networked {
      syncTransform: true,
      syncAnimation: true,
      syncExpression: true,
      interpolation: "smooth",
      updateRate: 30
    }
    @body_tracking {
      source: "headset",  // VR headset tracking
      ik_mode: "full_body"
    }

    model: bind(localPlayerAvatar),
    position: bind(localPlayerPosition)
  }

  // Template for remote player avatars
  template "RemotePlayerTemplate" {
    @skeleton { rig: "humanoid" }
    @face { expressions: "full" }
    @expressive { lipSync: true }
    @networked {
      isRemote: true,
      interpolation: "smooth"
    }

    on_pose_change(pose) {
      // Applied automatically from network sync
    }

    on_expression_change(expression) {
      // Applied automatically from network sync
    }
  }

  // Network events
  logic {
    on_player_join(playerId, avatarUrl) {
      // Spawn remote player avatar
      const avatar = spawn("RemotePlayer_" + playerId, {
        template: "RemotePlayerTemplate",
        model: avatarUrl
      })
      state.remotePlayers[playerId] = avatar
    }

    on_player_leave(playerId) {
      if (state.remotePlayers[playerId]) {
        despawn(state.remotePlayers[playerId])
        delete state.remotePlayers[playerId]
      }
    }
  }
}

// ============================================================================
// EXAMPLE 5: Poseable Avatar for Screenshots/Art
// ============================================================================

composition "AvatarPoseStudio" {
  environment {
    skybox: "photo_studio",
    lighting: "three_point"
  }

  state {
    currentPose: "default",
    savedPoses: []
  }

  object "PoseableAvatar" {
    @skeleton {
      rig: "humanoid",
      editable: true
    }
    @face {
      expressions: "full",
      editable: true
    }
    @poseable {
      enabled: true,
      snapToGrid: false,
      mirrorMode: false,
      constrainJoints: true
    }
    @morph {
      targets: ["body_shape", "muscle_definition", "height_adjust"],
      editable: true
    }

    model: "https://example.com/avatars/base_avatar.vrm",
    position: [0, 0, -2]

    action setPose(poseName) {
      const pose = loadPose(poseName)
      self.applyPose(pose, { duration: 0.5 })
      state.currentPose = poseName
    }

    action savePose(name) {
      const currentPose = self.capturePose()
      state.savedPoses.push({ name, pose: currentPose })
    }

    on_pose_save(pose) {
      emit("pose_saved", { pose, timestamp: Date.now() })
    }
  }

  // Pose control UI
  ui {
    element "PoseControls" {
      type: "panel",
      position: "right",

      element "PoseList" {
        type: "list",
        items: bind(state.savedPoses),
        onSelect: (pose) => PoseableAvatar.setPose(pose.name)
      }

      element "SavePoseButton" {
        type: "button",
        label: "Save Current Pose",
        onClick: () => {
          const name = prompt("Pose name:")
          if (name) PoseableAvatar.savePose(name)
        }
      }
    }
  }
}

// ============================================================================
// TypeScript/JavaScript Integration Example
// ============================================================================

/*
// Using HumanoidLoader directly in TypeScript:

import {
  HumanoidLoader,
  createHumanoidLoader,
  loadHumanoid
} from '@holoscript/core';
import * as THREE from 'three';

async function loadAvatar() {
  // Create loader
  const loader = createHumanoidLoader();
  await loader.initialize();

  // Load VRM avatar
  const vrmResult = await loader.loadAvatar('mainCharacter', {
    url: 'https://example.com/avatar.vrm',
    scale: 1.0,
    enableIK: true,
    enableExpressions: true,
    enableLookAt: true,
    enableSpringBones: true,
  });

  // Load Ready Player Me avatar
  const rpmResult = await loader.loadAvatar('playerAvatar', {
    url: '64f8a1b2c3d4e5f6a7b8c9d0', // RPM avatar ID
    format: 'rpm',
    rpm: {
      quality: 'high',
      morphTargets: 'ARKit,Oculus Visemes',
      useDraco: true,
    },
  });

  // Control avatar
  loader.setExpression('mainCharacter', 'happy', 0.8);
  loader.setLookAt('mainCharacter', { x: 0, y: 1.6, z: 0 });

  // Apply pose from body tracking
  loader.applyPose('mainCharacter', {
    timestamp: Date.now(),
    rootTransform: {
      position: { x: 0, y: 0, z: 0 },
      rotation: { x: 0, y: 0, z: 0, w: 1 },
    },
    bones: [
      { name: 'leftUpperArm', position: { x: 0, y: 0, z: 0 }, rotation: { x: 0.1, y: 0, z: 0.5, w: 0.86 } },
      // ... more bones
    ],
  });

  // Listen for events
  loader.on('expression-change', (event) => {
    console.log(`Expression changed: ${event.data.expression}`);
  });

  // Add to Three.js scene
  const scene = new THREE.Scene();
  scene.add(vrmResult.data);
  scene.add(rpmResult.data);

  // Animation loop
  function animate() {
    requestAnimationFrame(animate);

    // Update VRM (spring bones, look-at, etc.)
    if (vrmResult.vrm) {
      vrmResult.vrm.update(delta);
    }
  }
  animate();
}
*/
